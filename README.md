# ğŸµ Music Assistant based on LLMs & NLP

> **Trabajo de Fin de Grado (TFG) - Grado en IngenierÃ­a InformÃ¡tica**
> 
> *Escuela TÃ©cnica Superior de IngenierÃ­a (ETSI), Universidad de Huelva*
>
> **Autor:** AntÃ³n Maestre GÃ³mez | **Tutor:** Jacinto Mata VÃ¡zquez

[![Python](https://img.shields.io/badge/PYTHON-3776AB?style=for-the-badge&logo=python&logoColor=white)](https://www.python.org/)
[![TypeScript](https://img.shields.io/badge/TYPESCRIPT-3178C6?style=for-the-badge&logo=typescript&logoColor=white)](https://www.typescriptlang.org/)
[![React](https://img.shields.io/badge/REACT-61DAFB?style=for-the-badge&logo=react&logoColor=black)](https://react.dev/)

[![Hugging Face](https://img.shields.io/badge/HUGGING_FACE-FFD21E?style=for-the-badge&logo=huggingface&logoColor=black)](https://huggingface.co/)
[![Google Colab](https://img.shields.io/badge/GOOGLE_COLAB-F9AB00?style=for-the-badge&logo=googlecolab&logoColor=white)](https://colab.research.google.com/)
[![PEFT LoRA](https://img.shields.io/badge/PEFT_/_LoRA-D00000?style=for-the-badge)](https://huggingface.co/docs/peft/index)

[![Flask](https://img.shields.io/badge/FLASK-000000?style=for-the-badge&logo=flask&logoColor=white)](https://flask.palletsprojects.com/)
[![DialogueKit](https://img.shields.io/badge/DIALOGUE_KIT-1155cc?style=for-the-badge)](https://github.com/iai-group/DialogueKit)

[![License](https://img.shields.io/badge/LICENSE-MIT-green?style=for-the-badge)](https://opensource.org/licenses/MIT)

## ğŸ“„ DescripciÃ³n del Proyecto

Este proyecto presenta el desarrollo de un **asistente musical conversacional** capaz de interpretar peticiones en lenguaje natural y gestionar una lista de reproducciÃ³n en tiempo real.

A diferencia de los asistentes tradicionales basados en comandos rÃ­gidos, este sistema utiliza **Modelos de Lenguaje Generativos (LLMs)** ajustados mediante tÃ©cnicas de *Fine-Tuning* para clasificar la intenciÃ³n del usuario. El sistema actÃºa como un orquestador inteligente que traduce lenguaje natural en operaciones SQL sobre una base de datos musical.

### Funcionalidades Principales
El modelo clasifica cada interacciÃ³n del usuario en una de las cuatro intenciones soportadas:
*   âœ… **Add:** AÃ±adir una canciÃ³n especÃ­fica a la playlist (ej: *"Pon 'Bohemian Rhapsody' de Queen"*).
*   âŒ **Remove:** Eliminar una canciÃ³n concreta (ej: *"Quita esa canciÃ³n de la lista"*).
*   ğŸ‘€ **View:** Consultar el estado actual de la lista de reproducciÃ³n.
*   ğŸ—‘ï¸ **Clear:** Vaciar la lista completa de golpe.

---

## ğŸ§  Modelos y MetodologÃ­a

Para este trabajo se han comparado, optimizado y desplegado dos arquitecturas de *State-of-the-Art*:

| Modelo | ParÃ¡metros | Tipo | DescripciÃ³n |
| :--- | :--- | :--- | :--- |
| **LLaMA-3.2-1B-Instruct** | 1.2B | Meta | Modelo ligero optimizado para seguir instrucciones. |
| **Falcon-7B** | 7B | TII | Modelo entrenado en el corpus masivo RefinedWeb. |

### ğŸ”¬ Entrenamiento y OptimizaciÃ³n
*   **Dataset:** 1600 frases sintÃ©ticas generadas con ChatGPT, balanceadas perfectamente entre las 4 clases (400 ejemplos/clase).
*   **Fine-Tuning:** Se utilizÃ³ **LoRA (Low-Rank Adaptation)** para reentrenar los modelos en GPUs T4 de Google Colab, reduciendo drÃ¡sticamente el consumo de VRAM.
*   **HiperparÃ¡metros:** Ajustados mediante OptimizaciÃ³n Bayesiana con **Optuna**.

### ğŸ“Š Resultados
Ambos modelos alcanzaron una **Exactitud (Accuracy) del 86.3%** en el conjunto de test, superando ampliamente a los *baselines* zero-shot (69-75%).

| MÃ©trica | LLaMA-1B (Tuned) | Falcon-7B (Tuned) |
| :--- | :--- | :--- |
| **Accuracy** | **86.3%** | **86.3%** |
| **Precision** | 0.87 | 0.89 |
| **Recall** | 0.86 | 0.86 |
| **F1-Score** | 0.86 | 0.86 |

---

## ğŸ“‚ Estructura del Repositorio

```text
tfg_music_assistant
â”œâ”€â”€ chatwidget/                   # FRONTEND AND DIALOG LOGIC
â”‚   â”œâ”€â”€ music_recommender.py          # Main script (Chatbot orchestrator with DialogueKit)
â”‚   â””â”€â”€ chatwidget.md                 # Enlace al cÃ³digo fuente del chatwidget
â”‚
â”œâ”€â”€ colab_notebooks/              # ENTRENAMIENTO E INFERENCIA
â”‚   â”œâ”€â”€ data/                         # Dataset (train.csv, test.csv, eval.csv)
â”‚   â”œâ”€â”€ ft_*_model/                   # Results and final models
â”‚   â”œâ”€â”€ api*.ipynb                    # Scripts de despliegues API 
â”‚   â”œâ”€â”€ Finetuning_*.ipynb            # Training notebooks with LoRA and Optuna
â”‚   â”œâ”€â”€ MergeModels.ipynb             # Script to merge LoRA weights with base model
â”‚   â””â”€â”€ EvalLossPlot.ipynb            # Loss plots (TensorBoard)
â”‚
â””â”€â”€ docs/                         # ACADEMIC DOCUMENTATION
    â”œâ”€â”€ memoria.pdf                   # Full Thesis Report (PDF)
    â”œâ”€â”€ PresentacionTFG.pdf           # Defense Presentation Slides
    â””â”€â”€ PruebaChat.mp4                # Demo video
```
---

## ğŸ› ï¸ Stack TecnolÃ³gico

*   **Lenguajes:** Python 3.10+, TypeScript.
*   **Deep Learning:** PyTorch, Transformers (Hugging Face), PEFT (LoRA).
*   **OptimizaciÃ³n:** Optuna (BÃºsqueda Bayesiana de HiperparÃ¡metros).
*   **Backend:** Flask, DialogueKit (IAI Group).
*   **Frontend:** React, WebSockets.
*   **Base de Datos:** SQLite (CatÃ¡logo de 1M+ de canciones).
*   **Infraestructura:** Google Colab (GPU T4), Localtunnel.

---

## ğŸ“ Referencias
Este trabajo se fundamenta en la investigaciÃ³n de modelos generativos y su aplicaciÃ³n en PLN. Para mÃ¡s detalles tÃ©cnicos, consultar la carpeta `/docs`.

*   *Maestre GÃ³mez, A. (2025). Desarrollo de un Sistema Asistente de MÃºsica Basado en Aprendizaje AutomÃ¡tico.* Universidad de Huelva.
*  ([https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct](https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct))
*  ([https://huggingface.co/tiiuae/falcon-7b](https://huggingface.co/tiiuae/falcon-7b))
